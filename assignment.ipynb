{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Anomaly detection is the process of identifying data points, events, or patterns that deviate significantly from the majority of data. \n",
    "Its purpose is to detect rare or unusual occurrences, such as fraud, equipment failure, or network intrusions.\n",
    "\n",
    "# Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Imbalanced data: Anomalies are rare compared to normal data.\n",
    "High-dimensional data: Curse of dimensionality can reduce algorithm efficiency.\n",
    "Dynamic behavior: Patterns can change over time.\n",
    "Lack of labeled data: Difficult to train supervised models.\n",
    "\n",
    "# Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "Unsupervised anomaly detection does not require labeled data and identifies anomalies based on inherent patterns or deviations.\n",
    "Supervised anomaly detection requires labeled data with normal and anomalous examples for model training.\n",
    "\n",
    "# Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Statistical methods: Based on probability distributions.\n",
    "Distance-based methods: Measure proximity or density of points.\n",
    "Clustering-based methods: Use cluster properties to detect outliers.\n",
    "Machine learning methods: Use models like Isolation Forest, LOF, or neural networks.\n",
    "\n",
    "# Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Anomalies are far from other data points in terms of distance.\n",
    "Normal data points form dense clusters, while anomalies are sparse or isolated.\n",
    "\n",
    "# Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "LOF (Local Outlier Factor) computes anomaly scores by comparing the local density of a data point to the densities of its neighbors. \n",
    "Points with significantly lower densities than their neighbors are considered anomalies.\n",
    "\n",
    "# Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Number of trees: Controls the size of the ensemble.\n",
    "Sub-sample size: The number of data points sampled to create each tree.\n",
    "Contamination: The expected proportion of anomalies in the data.\n",
    "\n",
    "# Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "\n",
    "If K=10 and the point has only 2 neighbors within the radius, it suggests a low density, leading to a high anomaly score since it lacks sufficient \n",
    "neighbors compared to normal data.\n",
    "\n",
    "# Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an \n",
    "# average path length of 5.0 compared to the average path length of the trees?\n",
    "\n",
    "The anomaly score is calculated as:\n",
    "\n",
    "s(x) = 2^ (-path length(x)/ average pathlength)\n",
    "\n",
    "If the average path length of the trees is greater than 5.0, s(x) will indicate a high likelihood of anomaly (closer to 1). If 5.0 is close to the \n",
    "expected average, s(x) suggests the point is less anomalous.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
